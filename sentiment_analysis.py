# -*- coding: utf-8 -*-
"""Sentiment_Analysis_Shola_Ayeotan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11ulxa2fUERbJKGP4OyA-3FimKBA7bJTB
"""

# Importing the necessary libraries

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import re
import itertools
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.tokenize import word_tokenize
nltk.download('punkt')
from nltk.probability import FreqDist
from sklearn.feature_extraction.text import CountVectorizer

import warnings
warnings.filterwarnings('ignore')

"""### **Loading the dataset**"""

# Loading the tweets into a dataframe

climateDF = pd.read_csv('/content/climate-tweets.csv')

climateDF.head()

"""### **Cleaning and Tokenization**"""

# Removing unwanted elements (punctuations, whitespace, usernames, URLs, Hashtags etc.)
def clean_text(d):
    d = d.lower()

    to_del = [
        r"@[\w]*",
        r"http(s?):\/\/.*\/\w*",
        r"#\w*",
        r"\d+",
        r"U+FFFD",]

    for key in to_del:
        d = re.sub(key, "", d)

    d = re.sub(r"[,.;':@#?!\&/$]+\ *", " ", d)
    d = re.sub(r"\s\s+", " ", d)

    return d.lstrip(" ")


# Removing stopwords
def clean_stopword(d):
    stop_words = stopwords.words('english')
    return " ".join([w.lower() for w in d.split() if w.lower() not in stop_words and len(w) > 1])


# Tokenizing the tweets

def tokenize(d):
    return word_tokenize(d)

# def tokenize(d):
#     tokens = word_tokenize(d)
#     return " ".join(tokens)

# Applying the functions
climateDF['tokenized_tweets']= climateDF.tweets.apply(clean_text)\
                          .apply(clean_stopword).apply(tokenize)

climateDF.head()



"""### **Sentiment Analysis**"""

from nltk.sentiment.vader import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')

# Initializing VADER
sia = SentimentIntensityAnalyzer()

# Defining a function to calculate polarity scores
def get_sentiment_score(tweet):
    sentiment = sia.polarity_scores(tweet)
    return sentiment['compound']

# Initializing the function
climateDF['sentiment_score']= climateDF['tweets'].apply(get_sentiment_score)

climateDF.head()

# Creating the sentiment labels

threshold = 0.05

climateDF['sentiment'] = [
    1 if compound >= threshold else (
    -1 if compound <= -threshold else 0)
    for compound in climateDF['sentiment_score']]

climateDF.head()

climateDF.describe()

climateDF['sentiment'].describe()

"""### **Data Preprocessing**"""

# Conducting feature extraction

X = climateDF[['tweets', 'tweetid', 'sentiment_score']]
y = climateDF['sentiment']

"""### **Exploratory Data Analysis**"""

# Checking for the unique values in the dataset

climateDF.sentiment.value_counts()

# Visualizing the sentiment distribution

plt.figure(figsize=(13, 8))
count_plot = sns.countplot(data=climateDF, y='sentiment', palette='Set2')
count_plot.bar_label(count_plot.containers[0], fmt='%d')

plt.title('Sentiment Distribution in Climate Tweets')
plt.xlabel('Frequency')
plt.ylabel('Sentiment')
plt.show()

# Plotting a pie chart

plt.figure(figsize=(8, 8))

labels = climateDF.sentiment.unique()
sentiment_counts = climateDF["sentiment"].value_counts()
colors = ['skyblue', 'lightcoral', 'lightgreen']

plt.pie(sentiment_counts,
        labels=labels,
        autopct="%1.0f%%",
        startangle=90,
        explode=tuple([0.1] * len(labels)),
        colors=colors)

plt.title('Sentiment Distribution in Climate Data', fontsize=16)
plt.xlabel('Sentiment Categories', fontsize=14)
plt.ylabel('Count', fontsize=14)

plt.show()

plt.figure(figsize=(8, 6))

sns.boxplot(x="sentiment", y=climateDF["tokenized_tweets"].str.len(), data=climateDF, palette="Set3")

plt.title("Distribution of Tweet Length for Each Sentiment", fontsize=16)
plt.xlabel("Sentiment", fontsize=14)
plt.ylabel("Tweet Length", fontsize=14)

plt.show()

"""#### **Developing WordClouds**"""

from wordcloud import WordCloud

# Extract the buzzwords from each class

pro = climateDF[climateDF.sentiment == 1].tweets.apply(clean_text).apply(clean_stopword)
pro = " ".join(pro)

anti = climateDF[climateDF.sentiment == -1].tweets.apply(clean_text).apply(clean_stopword)
anti = " ".join(anti)

neutral = climateDF[climateDF.sentiment == 0].tweets.apply(clean_text).apply(clean_stopword)
neutral = " ".join(neutral)

from IPython.display import display

plt.figure(figsize=(18, 15))

wordcloudPro = WordCloud(min_font_size=3, max_words=200, width=1600, height=720,
                   colormap='viridis', background_color='white').generate(pro)

plt.imshow(wordcloudPro, interpolation='bilinear')
plt.title('Word Cloud for Pro Climate Sentiments', fontsize=30)
plt.xticks([])
plt.yticks([])
plt.grid(False)

plt.show()

plt.figure(figsize=(18, 15))

wordcloudAnti = WordCloud(min_font_size=3, max_words=200, width=1600, height=720,
                    colormap='Paired', background_color='white').generate(anti)

plt.imshow(wordcloudAnti, interpolation='bilinear')
plt.title('Word Cloud for Anti Climate Sentiments', fontsize=20)
plt.xticks([])
plt.yticks([])
plt.grid(False)

plt.show()

plt.figure(figsize=(18, 15))

wordcloudNeutral = WordCloud(min_font_size=3, max_words=200, width=1600, height=720,
                               colormap='tab10', background_color='white').generate(neutral)

plt.imshow(wordcloudNeutral, interpolation='bilinear')
plt.title('Word Cloud for Neutral Sentiments', fontsize=30)
plt.xticks([])
plt.yticks([])
plt.grid(False)

plt.show()

# Creating a frequency distribution of top 20 words

top20 = {}

for sentiment, group in climateDF.groupby("sentiment"):
    freq_words = group["tweets"].apply(lambda tweet: re.findall(r"#(\w+)", tweet))
    freq_words = itertools.chain(*freq_words)
    freq_words = [ht.lower() for ht in freq_words]

    frequency = nltk.FreqDist(freq_words)

    df_freq_words = pd.DataFrame({
        "freq_words": list(frequency.keys()),
        "counts": list(frequency.values()),
    })
    top20_htags = df_freq_words.nlargest(20, columns=["counts"])

    top20[sentiment] = top20_htags.reset_index(drop=True)

# Visualizing the frequency distribution

pro_climate_data = top20[1]

plt.figure(figsize=(15, 10))
sns.barplot(data=pro_climate_data,
            y="freq_words",
            x="counts",
            palette='crest')
plt.title("Most frequent words reflecting Pro Climate Sentiments", fontsize=20)
plt.show()

neutral_climate_data = top20[0]

plt.figure(figsize=(15, 10))
sns.barplot(data=neutral_climate_data,
            y="freq_words",
            x="counts",
            palette='mako')
plt.title("Most frequent words reflecting Neutral Climate Sentiments", fontsize=20)
plt.show()

anti_climate_data = top20[-1]

plt.figure(figsize=(15, 10))
sns.barplot(data=anti_climate_data,
            y="freq_words",
            x="counts",
            palette='Reds')
plt.title("Most frequent words reflecting Anti Climate Sentiments", fontsize=20)
plt.show()

"""### **Model Development**"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import *

# Splitting the dataset

X = climateDF["tweets"]
y = climateDF["sentiment"]

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Transform the tweets into a matrix for analysis

tfidf = TfidfVectorizer()
tfidf.fit_transform(X_train)

# Creating a list of sentiment classes

sentiment_classes = sorted(['-1', '1', '0'])

"""**Logistic Regression Model**"""

# Initializing the Logistic Regression model
logModel = LogisticRegression(class_weight="balanced", max_iter=1000)

# Training the Logistic Regression model
logModel.fit(tfidf.transform(X_train), Y_train)

# Making predictions on the test set
logPred = logModel.predict(tfidf.transform(X_test))

# Generating the confusion matrix heatmap

print(f"Accuracy Score: {accuracy_score(Y_test,logPred)*100:.2f}%")

# Generating the classification report
print("Classification Report:")
print(classification_report(Y_test,logPred))

cm = confusion_matrix(Y_test,logPred)
ax = sns.heatmap(cm, cmap='flare',annot=True, fmt='d')

plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12),
xticklabels = sentiment_classes,
yticklabels = sentiment_classes,
plt.show()

"""**Random Forest**"""

# Initializing the Random Forest model
rfModel = RandomForestClassifier(n_estimators=100, criterion = 'gini', max_features = 'log2')

# Fitting the model on the training data
rfModel.fit(tfidf.transform(X_train), Y_train)

# Running predictions on the test set
rfPred = rfModel.predict(tfidf.transform(X_test))

# Generating the confusion matrix heatmap

print(f"Accuracy Score: {accuracy_score(Y_test,rfPred)*100:.2f}%")

# Generating the classification report
print("Classification Report:")
print(classification_report(Y_test,rfPred))

cm = confusion_matrix(Y_test,rfPred)
ax = sns.heatmap(cm, cmap='flare',annot=True, fmt='d')

plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12),
xticklabels = sentiment_classes,
yticklabels = sentiment_classes,
plt.show()